{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2932b4ed-a923-4e8e-a309-030fd438b8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9b5b105-d0f0-4cb3-bce3-5ded36c4ce9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"practice\").getOrCreate()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ea6061bd-425e-4493-a5ca-1104e2d1239e",
   "metadata": {},
   "source": [
    "creating a sparkSession with the above line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82f7d026-9c23-4cb9-a6fb-88209eb30988",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyspark_df = spark.read.csv(\"test.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8e4a77bb-3718-4a40-a6e5-a0dab41a0f4d",
   "metadata": {},
   "source": [
    "without the \"option\" the spark takes the feildName as a data, to solve this we need to add \"option\" saying header is true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9a77c34-d0e3-4e92-8536-c8834211893a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----+------+\n",
      "|   name| age| exp|salary|\n",
      "+-------+----+----+------+\n",
      "|karthik|  20|   1| 10000|\n",
      "|  gokul|  35|  10|  NULL|\n",
      "|   subu|  25|   4| 20000|\n",
      "|   ram |NULL|   1| 10000|\n",
      "| muthu |  45|  20| 80000|\n",
      "|kishore|  32|  10| 25000|\n",
      "|   john|  27|NULL| 15000|\n",
      "|aravind|  34|  10| 25000|\n",
      "|   arun|  26|   5| 10000|\n",
      "+-------+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pyspark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b077033b-23eb-4753-b9e4-81c880f479b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pyspark_df)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "55705f06-564e-4b7c-a3cd-2e69bc132f7f",
   "metadata": {},
   "source": [
    "instead of pandas.core dataframe it is a sql dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abeced3e-00fd-431d-af53-1f7741a8fd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- exp: integer (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pyspark_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cef8b5f9-1c7d-4f1e-a097-b2d639bee087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name', 'age', 'exp', 'salary']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyspark_df.columns"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fdf12f1d-e48a-4c84-a26e-2a5e71e12bf7",
   "metadata": {},
   "source": [
    "to select a perticular column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78c65373-254b-487f-884a-faafaccd1545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|   name|\n",
      "+-------+\n",
      "|karthik|\n",
      "|  gokul|\n",
      "|   subu|\n",
      "|   ram |\n",
      "| muthu |\n",
      "|kishore|\n",
      "|   john|\n",
      "|aravind|\n",
      "|   arun|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pyspark_df.select('name').show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "78cbb72a-2d1b-4261-86f5-ee594897ab24",
   "metadata": {},
   "source": [
    "for multiple colunms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbafa6f3-5813-4ecf-9b7c-8635dcb556f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+\n",
      "|   name| age|\n",
      "+-------+----+\n",
      "|karthik|  20|\n",
      "|  gokul|  35|\n",
      "|   subu|  25|\n",
      "|   ram |NULL|\n",
      "| muthu |  45|\n",
      "|kishore|  32|\n",
      "|   john|  27|\n",
      "|aravind|  34|\n",
      "|   arun|  26|\n",
      "+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pyspark_df.select('name', 'age').show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4b9ebc14-f460-450b-9559-ec53ca9098b2",
   "metadata": {},
   "source": [
    "slicing is not supported in pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9667b9be-f095-41ad-9652-896f846fb395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('name', 'string'), ('age', 'int'), ('exp', 'int'), ('salary', 'int')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyspark_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be2d3fce-e628-47e0-a2f1-fbb5aeb41d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----------------+-----------------+-----------------+\n",
      "|summary|   name|              age|              exp|           salary|\n",
      "+-------+-------+-----------------+-----------------+-----------------+\n",
      "|  count|      9|                8|                8|                8|\n",
      "|   mean|   NULL|             30.5|            7.625|          24375.0|\n",
      "| stddev|   NULL|7.727501906456298|6.300510183423925|23366.26078038895|\n",
      "|    min|aravind|               20|                1|            10000|\n",
      "|    max|   subu|               45|               20|            80000|\n",
      "+-------+-------+-----------------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pyspark_df.describe().show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "613821e7-b69e-4d17-aced-6d1e8c92aa4d",
   "metadata": {},
   "source": [
    "adding and dropping columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9eaf108-762b-4a46-9867-18b538d034dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyspark_df = pyspark_df.withColumn('Age after 2 yrs',pyspark_df['age']+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54576b5d-b01b-4ed7-9d08-63680078d2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----+------+---------------+\n",
      "|   name| age| exp|salary|Age after 2 yrs|\n",
      "+-------+----+----+------+---------------+\n",
      "|karthik|  20|   1| 10000|             22|\n",
      "|  gokul|  35|  10|  NULL|             37|\n",
      "|   subu|  25|   4| 20000|             27|\n",
      "|   ram |NULL|   1| 10000|           NULL|\n",
      "| muthu |  45|  20| 80000|             47|\n",
      "|kishore|  32|  10| 25000|             34|\n",
      "|   john|  27|NULL| 15000|             29|\n",
      "|aravind|  34|  10| 25000|             36|\n",
      "|   arun|  26|   5| 10000|             28|\n",
      "+-------+----+----+------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pyspark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6994464e-083a-4a73-9a68-3845611139c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyspark_df = pyspark_df.drop('Age after 2 yrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a5d6f93-8a88-49c2-bce3-e9116c66bd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----+------+\n",
      "|   name| age| exp|salary|\n",
      "+-------+----+----+------+\n",
      "|karthik|  20|   1| 10000|\n",
      "|  gokul|  35|  10|  NULL|\n",
      "|   subu|  25|   4| 20000|\n",
      "|   ram |NULL|   1| 10000|\n",
      "| muthu |  45|  20| 80000|\n",
      "|kishore|  32|  10| 25000|\n",
      "|   john|  27|NULL| 15000|\n",
      "|aravind|  34|  10| 25000|\n",
      "|   arun|  26|   5| 10000|\n",
      "+-------+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pyspark_df.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1e678c40-b2f5-4d27-847c-52caab8e1ac2",
   "metadata": {},
   "source": [
    "renaming columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3f3ebd7-9f8b-413e-a236-339e766e41c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----+------+\n",
      "|full name| age| exp|salary|\n",
      "+---------+----+----+------+\n",
      "|  karthik|  20|   1| 10000|\n",
      "|    gokul|  35|  10|  NULL|\n",
      "|     subu|  25|   4| 20000|\n",
      "|     ram |NULL|   1| 10000|\n",
      "|   muthu |  45|  20| 80000|\n",
      "|  kishore|  32|  10| 25000|\n",
      "|     john|  27|NULL| 15000|\n",
      "|  aravind|  34|  10| 25000|\n",
      "|     arun|  26|   5| 10000|\n",
      "+---------+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pyspark_df.withColumnRenamed('name', 'full name').show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "561b064f-3716-42a5-9a49-7a69d73f5144",
   "metadata": {},
   "source": [
    "Handling missing and null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70e9e47a-d541-4527-82b6-525a29daf9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----+------+\n",
      "|   name| age| exp|salary|\n",
      "+-------+----+----+------+\n",
      "|karthik|  20|   1| 10000|\n",
      "|  gokul|  35|  10|  NULL|\n",
      "|   subu|  25|   4| 20000|\n",
      "|   ram |NULL|   1| 10000|\n",
      "| muthu |  45|  20| 80000|\n",
      "|kishore|  32|  10| 25000|\n",
      "|   john|  27|NULL| 15000|\n",
      "|aravind|  34|  10| 25000|\n",
      "|   arun|  26|   5| 10000|\n",
      "+-------+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pyspark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "097416ac-9426-4908-8e0e-df0394164e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pyspark_df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f4ff750f-5282-44d4-98ea-768365326bf7",
   "metadata": {},
   "source": [
    "drop rows where null is present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40947fc3-f50f-4b07-9368-1dc0f26ac40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+---+------+\n",
      "|   name|age|exp|salary|\n",
      "+-------+---+---+------+\n",
      "|karthik| 20|  1| 10000|\n",
      "|   subu| 25|  4| 20000|\n",
      "| muthu | 45| 20| 80000|\n",
      "|kishore| 32| 10| 25000|\n",
      "|aravind| 34| 10| 25000|\n",
      "|   arun| 26|  5| 10000|\n",
      "+-------+---+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop().show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "859ed09b-798d-43a7-bce9-f0997b455818",
   "metadata": {},
   "source": [
    "drop function has 3 parameters\n",
    "- how = all/any\n",
    "- threshold = int - minimum no of non null values in a row\n",
    "- subset = takes in column name, drops all null values in that column"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f2e6e2ee-3388-4581-ba6d-382813acf434",
   "metadata": {},
   "source": [
    "filling missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e82b0457-9943-4b20-bd48-79e3bf6ba2b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, exp: string]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('exp').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fdb9f99e-6b7c-4ed1-bec0-a9844b38d3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParallelCollectionRDD[54] at readRDDFromFile at PythonRDD.scala:289\n"
     ]
    }
   ],
   "source": [
    "dataList = [(\"Java\", 20000), (\"Python\", 100000), (\"Scala\", 3000)]\n",
    "rdd=spark.sparkContext.parallelize(dataList)\n",
    "print(rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2d4f6b-6918-4385-a21f-80408bef4f8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
